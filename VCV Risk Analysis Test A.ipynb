{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49a6a7-43c2-468a-8b9e-caccac667ad9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define tickers and positions\n",
    "tickers = ['AMD', 'META', 'VUAA.MI', 'VUSA.L', 'ELF', 'NKE', 'SOFI', 'HNST', 'NVDA']\n",
    "positions = np.array([6.8559989, 0.4774942, 2.4546871, 2.6402322, 2.529204, 3.06302, 10.53165, 20.41967, 1.0183181])\n",
    "positions_series = pd.Series(positions, index=tickers)\n",
    "\n",
    "# Download latest closing prices\n",
    "data = yf.download(tickers, period='5d', interval='1d')['Close']\n",
    "latest_prices = data.ffill().iloc[-1].dropna()\n",
    "\n",
    "# Align positions with available tickers\n",
    "positions_series = positions_series[latest_prices.index]\n",
    "\n",
    "# Download FX rates\n",
    "eurusd = float(yf.download('EURUSD=X', period='5d')['Close'].ffill().iloc[-1])\n",
    "gbpeur = float(yf.download('GBPEUR=X', period='5d')['Close'].ffill().iloc[-1])\n",
    "\n",
    "# Convert prices to EUR\n",
    "converted_prices = []\n",
    "for ticker, price in latest_prices.items():\n",
    "    if ticker.endswith('.L'):\n",
    "        converted_prices.append(price * gbpeur)  # GBP to EUR\n",
    "    else:\n",
    "        converted_prices.append(price / eurusd)  # USD to EUR\n",
    "\n",
    "converted_prices_series = pd.Series(converted_prices, index=latest_prices.index)\n",
    "\n",
    "# Calculate EUR values\n",
    "value_eur = positions_series * converted_prices_series\n",
    "portfolio_value = value_eur.sum()\n",
    "\n",
    "# Create summary table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Shares': positions_series,\n",
    "    'Price (EUR)': converted_prices_series.round(2),\n",
    "    'Value (EUR)': value_eur.round(2)\n",
    "})\n",
    "\n",
    "# Sort by largest position\n",
    "summary_df = summary_df.sort_values(by='Value (EUR)', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(summary_df.index, summary_df['Value (EUR)'])\n",
    "plt.title(\"âœ… Cleaned Portfolio Value by Ticker As of Today (in EUR)\")\n",
    "plt.ylabel(\"Value in EUR\")\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display summary\n",
    "print(\"ðŸ“Š Portfolio Breakdown in EUR:\")\n",
    "print(summary_df)\n",
    "print(\"\\nðŸ’¼ Total Portfolio Value in EUR:\", round(portfolio_value, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3287d5-46bb-4f1c-80ce-3a92cba7ed97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "tickers = ['AMD', 'META', 'VUAA.MI', 'VUSA.L', 'ELF', 'NKE', 'SOFI', 'HNST', 'NVDA']# You can add more tickers here\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "# Download the full data\n",
    "data = yf.download(tickers, start=start_date, end=end_date)\n",
    "\n",
    "# Check available keys (columns)\n",
    "print(\"Available keys:\", data.columns.levels[0])\n",
    "\n",
    "# Try to get 'Adj Close'; fallback to 'Close' if unavailable\n",
    "if 'Adj Close' in data.columns.levels[0]:\n",
    "    yahoo_data = data['Adj Close']\n",
    "elif 'Close' in data.columns.levels[0]:\n",
    "    yahoo_data = data['Close']\n",
    "else:\n",
    "    raise ValueError(\"Neither 'Adj Close' nor 'Close' data is available.\")\n",
    "\n",
    "yahoo_data.dropna(inplace=True)\n",
    "print(\"Yahoo Finance Data (cleaned):\")\n",
    "print(yahoo_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9a61f-a89c-4aaa-832c-51c9970377b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "returns = np.log(yahoo_data / yahoo_data.shift(1)).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42192383-eebc-41db-91e9-81736257b49a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. ðŸ“ˆ Line Chart: Daily Log Returns\n",
    "plt.figure(figsize=(12, 5))\n",
    "returns.plot(ax=plt.gca(), linewidth=1.2)\n",
    "plt.title(\"Daily Log Returns\")\n",
    "plt.ylabel(\"Log Return\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Push legend outside\n",
    "plt.show()\n",
    "\n",
    "# 2. ðŸ“Š Histogram Chart: Distribution of Each Asset's Daily Log Returns\n",
    "num_assets = returns.shape[1]\n",
    "cols = 3\n",
    "rows = (num_assets + cols - 1) // cols  # auto row count\n",
    "\n",
    "returns.hist(\n",
    "    bins=50,\n",
    "    figsize=(4 * cols, 3 * rows),\n",
    "    layout=(rows, cols),\n",
    "    edgecolor='black',\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Histogram of Daily Log Returns\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. ðŸ“‰ Print Volatilities\n",
    "print(\"Standard deviations (volatility) of daily log returns:\")\n",
    "print(returns.std().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f2a7f-393f-41c0-a6fb-0c9aa0c656c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = returns.cov()\n",
    "print(\"Covariance Matrix:\")\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0caaf32-60ab-4ab7-8f3c-5fff27925474",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Match tickers to positions\n",
    "positions = np.array([6.8559889, 0.4774942, 2.4546871, 2.640232, 2.529204, 3.063002, 10.53165, 20.41967, 1.0183108])  # Units: AAPL, MSFT, ^GSPC\n",
    "\n",
    "# Step 2: Get latest prices from data\n",
    "latest_prices = yahoo_data.iloc[-1]  # Last available date\n",
    "\n",
    "# Step 3: Calculate notional positions\n",
    "notional_positions = latest_prices.values * positions  # Element-wise multiplication\n",
    "\n",
    "# Step 4: Portfolio value and weights in â‚¬\n",
    "portfolio_value = notional_positions.sum()\n",
    "weights = notional_positions / portfolio_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90d633-8788-44c2-ae85-5041b47b8393",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute daily standard deviations (volatilities)\n",
    "asset_vols = returns.std()\n",
    "\n",
    "# Create bar chart with enhancements\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "bars = ax.bar(asset_vols.index, asset_vols.values, color='steelblue', edgecolor='black', linewidth=0.7)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        yval + 0.0005,\n",
    "        f'{yval:.4f}',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "# Improve readability\n",
    "ax.set_title('Asset Volatilities (Daily Std Dev)', fontsize=14)\n",
    "ax.set_ylabel('Daily Volatility (Std Dev)', fontsize=12)\n",
    "ax.set_xlabel('Asset', fontsize=12)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b8e99-6547-4246-a7a5-25429dd041e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Portfolio returns (from earlier)\n",
    "portfolio_returns = returns @ weights\n",
    "\n",
    "# CVaR function\n",
    "def compute_cvar(returns, alpha=0.95):\n",
    "    var = np.percentile(returns, (1 - alpha) * 100)\n",
    "    cvar = returns[returns <= var].mean()\n",
    "    return var, cvar\n",
    "\n",
    "for alpha in [0.95, 0.99]:\n",
    "    var, cvar = compute_cvar(portfolio_returns, alpha)\n",
    "\n",
    "    # Scale to â‚¬ terms\n",
    "    var_eur = abs(var * portfolio_value)\n",
    "    cvar_eur = abs(cvar * portfolio_value)\n",
    "\n",
    "    # Print both % and â‚¬\n",
    "    print(f\"{int(alpha*100)}% VaR:  {abs(var):.4%}  â†’  â‚¬{var_eur:,.2f}\")\n",
    "    print(f\"{int(alpha*100)}% CVaR: {abs(cvar):.4%}  â†’  â‚¬{cvar_eur:,.2f}\")\n",
    "    print(\"â€”\" * 40)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48bc01-ae3d-4108-a725-5b1be6ed6ad7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_var_cvar_exceedances(portfolio_returns, portfolio_value, window=20):\n",
    "    results = {}\n",
    "\n",
    "    for alpha, label in zip([0.95, 0.99], [\"95%\", \"99%\"]):\n",
    "        z_score = abs(np.round(np.percentile(np.random.normal(0, 1, 10**6), (1 - alpha) * 100), 3))\n",
    "\n",
    "        # Rolling volatility and thresholds\n",
    "        rolling_vol = portfolio_returns.rolling(window).std()\n",
    "        rolling_var = -z_score * rolling_vol\n",
    "        rolling_cvar = portfolio_returns.rolling(window).apply(\n",
    "            lambda x: x[x < x.quantile(1 - alpha)].mean(), raw=False\n",
    "        )\n",
    "\n",
    "        # Merge data\n",
    "        df = pd.DataFrame({\n",
    "            'Actual': portfolio_returns,\n",
    "            'VaR': rolling_var,\n",
    "            'CVaR': rolling_cvar\n",
    "        }).dropna()\n",
    "\n",
    "        # Exceedances\n",
    "        var_exceed = df['Actual'] < df['VaR']\n",
    "        cvar_exceed = df['Actual'] < df['CVaR']\n",
    "\n",
    "        # Accuracy metrics\n",
    "        var_count = var_exceed.sum()\n",
    "        cvar_count = cvar_exceed.sum()\n",
    "        n_obs = len(df)\n",
    "        expected_exceeds = int((1 - alpha) * n_obs)\n",
    "        failure_rate = var_count / n_obs\n",
    "        accuracy_rate = 1 - failure_rate\n",
    "\n",
    "        results[label] = {\n",
    "            \"Data\": df,\n",
    "            \"VaR Exceed Count\": int(var_count),\n",
    "            \"CVaR Exceed Count\": int(cvar_count),\n",
    "            \"Expected VaR Exceeds\": expected_exceeds,\n",
    "            \"Failure Rate (%)\": round(100 * failure_rate, 2),\n",
    "            \"Accuracy (%)\": round(100 * accuracy_rate, 2)\n",
    "        }\n",
    "\n",
    "        # ðŸ“ˆ VaR Exceedance Plot\n",
    "        fig, ax = plt.subplots(figsize=(14, 5))\n",
    "        ax.plot(df.index, df['Actual'], label='Actual Return', color='blue', linewidth=1.5)\n",
    "        ax.plot(df.index, df['VaR'], label=f'VaR {label}', linestyle='--', color='red', linewidth=2)\n",
    "        ax.scatter(df.index[var_exceed], df['Actual'][var_exceed],\n",
    "                   color='red', label='VaR Exceeded', marker='x', s=80)\n",
    "\n",
    "        ax.set_title(f\"VaR Exceedances â€“ {label} Confidence Level\", fontsize=15)\n",
    "        ax.set_ylabel(\"Portfolio Daily Return\", fontsize=12)\n",
    "        ax.set_xlabel(\"Date\", fontsize=12)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # ðŸ“Š Summary Chart: VaR Robustness (Accuracy %)\n",
    "    conf_levels = sorted(results.keys())\n",
    "    accuracies = [results[cl][\"Accuracy (%)\"] for cl in conf_levels]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bars = plt.bar(conf_levels, accuracies, color='seagreen')\n",
    "    plt.ylim(0, 110)\n",
    "    plt.title(\"VaR Model Robustness (Accuracy %)\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 2, f'{acc:.1f}%',\n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"âœ… VaR robustness summary chart generated.\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aae5c6-3803-4a6f-8893-85b919e53670",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results = check_var_cvar_exceedances(portfolio_returns, portfolio_value)\n",
    "\n",
    "import pprint\n",
    "pprint.pprint({\n",
    "    k: {i: v for i, v in val.items() if i != 'Data'}\n",
    "    for k, val in results.items()\n",
    "})\n",
    "\n",
    "pd.DataFrame({\n",
    "    k: {\n",
    "        \"Accuracy (%)\": v[\"Accuracy (%)\"],\n",
    "        \"Failure Rate (%)\": v[\"Failure Rate (%)\"]\n",
    "    }\n",
    "    for k, v in results.items()\n",
    "}).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2e0ba-e721-4d15-ae47-68aed4ec60fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predefined z-scores for normal distribution\n",
    "z_scores = {'95%': 1.65, '99%': 2.326}\n",
    "colors = {'95%': 'darkorange', '99%': 'crimson'}\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for label in ['95%', '99%']:\n",
    "    z = z_scores[label]\n",
    "\n",
    "    # Rolling 20-day standard deviation\n",
    "    rolling_vol = portfolio_returns.rolling(20).std()\n",
    "\n",
    "    # Rolling VaR in monetary (â‚¬) terms\n",
    "    rolling_var = -z * rolling_vol * portfolio_value\n",
    "\n",
    "    # Plot each VaR line\n",
    "    plt.plot(rolling_var, label=f'{label} VaR (20-Day Rolling)', color=colors[label], linewidth=2)\n",
    "\n",
    "# Chart formatting\n",
    "plt.title(\"Rolling 20-Day VaR â€“ 95% vs 99% Confidence Levels\", fontsize=14)\n",
    "plt.ylabel(\"VaR (â‚¬)\", fontsize=12)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025a288-0a68-44d3-8752-c8d757b47180",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(returns.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Asset Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97685d4a-f1e2-40f7-851a-03623be2ac2e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compute portfolio volatility\n",
    "portfolio_std = portfolio_returns.std()\n",
    "\n",
    "# Z-scores for 95% and 99% confidence levels\n",
    "z_scores = {'95%': 1.65, '99%': 2.326}\n",
    "VaR_1d_95 = -z_scores['95%'] * portfolio_std\n",
    "VaR_1d_99 = -z_scores['99%'] * portfolio_std\n",
    "\n",
    "# Plot histogram of daily returns\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(portfolio_returns, bins=50, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add VaR threshold lines\n",
    "plt.axvline(VaR_1d_95, color='orange', linestyle='--', linewidth=2,\n",
    "            label=f\"95% VaR = {VaR_1d_95:.4f}\")\n",
    "plt.axvline(VaR_1d_99, color='red', linestyle='-.', linewidth=2,\n",
    "            label=f\"99% VaR = {VaR_1d_99:.4f}\")\n",
    "\n",
    "# Labels and legend\n",
    "plt.title(\"Portfolio Return Distribution with 1-Day VaR Thresholds\", fontsize=14)\n",
    "plt.xlabel(\"Daily Return\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fcd60e-5304-4bfc-9376-eb390711dff7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all warnings\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"yfinance\").setLevel(logging.CRITICAL)  # Silence yfinance logs\n",
    "\n",
    "\n",
    "def historical_stress_test(tickers, weights, start_date, end_date, label=\"March 2020 COVID Crash\", benchmark_tickers=None):\n",
    "    # 1. Download data for portfolio\n",
    "    raw_data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "\n",
    "    # 2. Drop missing tickers\n",
    "    valid_data = raw_data.dropna(axis=1, how='any')\n",
    "    available = valid_data.columns.tolist()\n",
    "    missing = [t for t in tickers if t not in available]\n",
    "\n",
    "    if len(available) == 0:\n",
    "        print(\"ðŸš« No assets have valid price data in the given window. Cannot compute stress test.\")\n",
    "        return None\n",
    "\n",
    "    if missing:\n",
    "        print(f\"â„¹ï¸ Missing tickers (excluded from stress test): {missing}\")\n",
    "\n",
    "\n",
    "    # 3. Align weights\n",
    "    filtered_indices = [tickers.index(t) for t in available]\n",
    "    filtered_weights = np.array(weights)[filtered_indices]\n",
    "    filtered_weights = filtered_weights / filtered_weights.sum()\n",
    "\n",
    "    # 4. Compute portfolio returns\n",
    "    returns = np.log(valid_data / valid_data.shift(1)).dropna()\n",
    "    portfolio_returns = returns @ filtered_weights\n",
    "    cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "\n",
    "    # 5. Download and compute benchmark returns if provided\n",
    "    benchmark_returns_dict = {}\n",
    "    benchmark_cumulative_dict = {}\n",
    "    if benchmark_tickers:\n",
    "        for bmark in benchmark_tickers:\n",
    "            try:\n",
    "                benchmark_prices = yf.download(bmark, start=start_date, end=end_date)['Close'].dropna()\n",
    "                benchmark_returns = np.log(benchmark_prices / benchmark_prices.shift(1)).dropna()\n",
    "\n",
    "                # Align with portfolio\n",
    "                aligned = pd.concat([portfolio_returns, benchmark_returns], axis=1).dropna()\n",
    "                aligned.columns = ['Portfolio', bmark]\n",
    "\n",
    "                portfolio_returns = aligned['Portfolio']\n",
    "                benchmark_returns = aligned[bmark]\n",
    "                benchmark_cumulative = (1 + benchmark_returns).cumprod()\n",
    "\n",
    "                benchmark_returns_dict[bmark] = benchmark_returns\n",
    "                benchmark_cumulative_dict[bmark] = benchmark_cumulative\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Could not download or align benchmark {bmark}: {e}\")\n",
    "\n",
    "    # 6. Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(cumulative_returns, label='Portfolio Cumulative Return', color='crimson', linewidth=2)\n",
    "\n",
    "    for bmark, bmark_cum in benchmark_cumulative_dict.items():\n",
    "        ax.plot(bmark_cum, label=f'{bmark} Cumulative Return', linestyle='--', linewidth=2)\n",
    "\n",
    "    ax.set_title(f\"ðŸ“‰ Historical Stress Test: {label}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Cumulative Return\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax.legend()\n",
    "\n",
    "    # Improve x-axis date visibility\n",
    "    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 7. Summary\n",
    "    summary = {\n",
    "        \"Scenario\": label,\n",
    "        \"Tickers Used\": available,\n",
    "        \"Start Value\": 1.0,\n",
    "        \"End Value\": round(cumulative_returns.iloc[-1], 4),\n",
    "        \"Total Return (%)\": round((cumulative_returns.iloc[-1] - 1) * 100, 2),\n",
    "        \"Max Drawdown (%)\": round(((cumulative_returns.cummax() - cumulative_returns).max()) * 100, 2),\n",
    "        \"Volatility (Daily Std Dev)\": round(portfolio_returns.std(), 4)\n",
    "    }\n",
    "\n",
    "    for bmark, bmark_ret in benchmark_returns_dict.items():\n",
    "        bmark_cum = benchmark_cumulative_dict[bmark]\n",
    "        summary[f\"{bmark} Benchmark Return (%)\"] = round((bmark_cum.iloc[-1] - 1) * 100, 2)\n",
    "        tracking_error = np.sqrt(np.mean((portfolio_returns - bmark_ret) ** 2))\n",
    "        correlation = np.corrcoef(portfolio_returns, bmark_ret)[0, 1]\n",
    "        summary[f\"{bmark} Tracking Error\"] = round(tracking_error, 4)\n",
    "        summary[f\"{bmark} Correlation\"] = round(correlation, 4)\n",
    "\n",
    "    print(\"\\nðŸ“Š Stress Test Summary:\")\n",
    "    pprint.pprint(summary)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c8183-9abe-47c8-aafc-24dec2046540",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summary = historical_stress_test(tickers, weights, start_date='2020-02-19', end_date='2020-03-23', benchmark_tickers=['^GSPC', '^IXIC'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8cd71-4f74-4bb4-9b47-ae48f10c07b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pprint\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"yfinance\").setLevel(logging.CRITICAL)\n",
    "\n",
    "def historical_stress_test(tickers, weights, start_date, end_date, label=\"March 2020 COVID Crash\", benchmark_tickers=None):\n",
    "    # 1. Download data for portfolio\n",
    "    raw_data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "\n",
    "    # 2. Drop missing tickers\n",
    "    valid_data = raw_data.dropna(axis=1, how='any')\n",
    "    available = valid_data.columns.tolist()\n",
    "    missing = [t for t in tickers if t not in available]\n",
    "\n",
    "    if len(available) == 0:\n",
    "        print(\"ðŸš« No assets have valid price data in the given window. Cannot compute stress test.\")\n",
    "        return None\n",
    "\n",
    "    if missing:\n",
    "        print(f\"â„¹ï¸ Missing tickers (excluded from stress test): {missing}\")\n",
    "\n",
    "    # 3. Align weights\n",
    "    filtered_indices = [tickers.index(t) for t in available]\n",
    "    filtered_weights = np.array(weights)[filtered_indices]\n",
    "    filtered_weights = filtered_weights / filtered_weights.sum()\n",
    "\n",
    "    # 4. Compute portfolio returns\n",
    "    returns = np.log(valid_data / valid_data.shift(1)).dropna()\n",
    "    portfolio_returns = returns @ filtered_weights\n",
    "    cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "\n",
    "    # 5. Download and compute benchmark returns if provided\n",
    "    benchmark_returns_dict = {}\n",
    "    benchmark_cumulative_dict = {}\n",
    "    if benchmark_tickers:\n",
    "        for bmark in benchmark_tickers:\n",
    "            try:\n",
    "                benchmark_prices = yf.download(bmark, start=start_date, end=end_date)['Close'].dropna()\n",
    "                benchmark_returns = np.log(benchmark_prices / benchmark_prices.shift(1)).dropna()\n",
    "\n",
    "                # Align with portfolio\n",
    "                aligned = pd.concat([portfolio_returns, benchmark_returns], axis=1).dropna()\n",
    "                aligned.columns = ['Portfolio', bmark]\n",
    "\n",
    "                portfolio_returns = aligned['Portfolio']\n",
    "                benchmark_returns = aligned[bmark]\n",
    "                benchmark_cumulative = (1 + benchmark_returns).cumprod()\n",
    "\n",
    "                benchmark_returns_dict[bmark] = benchmark_returns\n",
    "                benchmark_cumulative_dict[bmark] = benchmark_cumulative\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Could not download or align benchmark {bmark}: {e}\")\n",
    "\n",
    "    # 6. Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(cumulative_returns, label='Portfolio Cumulative Return', color='crimson', linewidth=2)\n",
    "\n",
    "    for bmark, bmark_cum in benchmark_cumulative_dict.items():\n",
    "        ax.plot(bmark_cum, label=f'{bmark} Cumulative Return', linestyle='--', linewidth=2)\n",
    "\n",
    "    ax.set_title(f\"ðŸ“‰ Historical Stress Test: {label}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Cumulative Return\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax.legend()\n",
    "\n",
    "    # Improve x-axis date visibility\n",
    "    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 7. Summary\n",
    "    summary = {\n",
    "        \"Scenario\": label,\n",
    "        \"Tickers Used\": available,\n",
    "        \"Start Value\": 1.0,\n",
    "        \"End Value\": round(cumulative_returns.iloc[-1], 4),\n",
    "        \"Total Return (%)\": round((cumulative_returns.iloc[-1] - 1) * 100, 2),\n",
    "        \"Max Drawdown (%)\": round(((cumulative_returns.cummax() - cumulative_returns).max()) * 100, 2),\n",
    "        \"Volatility (Daily Std Dev)\": round(portfolio_returns.std(), 4)\n",
    "    }\n",
    "\n",
    "    for bmark, bmark_ret in benchmark_returns_dict.items():\n",
    "        bmark_cum = benchmark_cumulative_dict[bmark]\n",
    "        summary[f\"{bmark} Benchmark Return (%)\"] = round((bmark_cum.iloc[-1] - 1) * 100, 2)\n",
    "        tracking_error = np.sqrt(np.mean((portfolio_returns - bmark_ret) ** 2))\n",
    "        correlation = np.corrcoef(portfolio_returns, bmark_ret)[0, 1]\n",
    "        summary[f\"{bmark} Tracking Error\"] = round(tracking_error, 4)\n",
    "        summary[f\"{bmark} Correlation\"] = round(correlation, 4)\n",
    "\n",
    "    print(\"\\nðŸ“Š Stress Test Summary:\")\n",
    "    pprint.pprint(summary)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Example for 2008 Global Financial Crisis\n",
    "# historical_stress_test(tickers, weights, start_date='2008-09-01', end_date='2009-03-01', label=\"2008 Global Financial Crisis\", benchmark_tickers=['^GSPC', '^IXIC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f437f-d570-4245-b61d-4f38e1ed5fd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summary = historical_stress_test(\n",
    "    tickers, \n",
    "    weights, \n",
    "    start_date='2008-09-01', \n",
    "    end_date='2009-03-01', \n",
    "    label=\"2008 Global Financial Crisis\", \n",
    "    benchmark_tickers=['^GSPC', '^IXIC']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa092ec-59a3-4d3a-bc7b-9a9a52f15e83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def compute_beta(asset_ret, market_ret):\n",
    "    cov = np.cov(asset_ret, market_ret)[0, 1]\n",
    "    market_var = np.var(market_ret)\n",
    "    return cov / market_var if market_var != 0 else 0\n",
    "\n",
    "def hypothetical_stress_test_sp500_shock(tickers, weights, shock_pct=0.10, label=\"S&P 500 +10%\", benchmark_tickers=None):\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=365)\n",
    "\n",
    "    data = yf.download(tickers + ['^GSPC'], start=start, end=end)['Close'].dropna()\n",
    "    returns = np.log(data / data.shift(1)).dropna()\n",
    "\n",
    "    if '^GSPC' not in returns.columns:\n",
    "        print(\"âŒ Could not compute returns vs. S&P 500.\")\n",
    "        return\n",
    "\n",
    "    market_ret = returns['^GSPC']\n",
    "    asset_betas = []\n",
    "    valid_tickers = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if ticker in returns.columns:\n",
    "            asset_ret = returns[ticker]\n",
    "            aligned = pd.concat([asset_ret, market_ret], axis=1).dropna()\n",
    "            beta = compute_beta(aligned[ticker], aligned['^GSPC'])\n",
    "            asset_betas.append(beta)\n",
    "            valid_tickers.append(ticker)\n",
    "\n",
    "    if not valid_tickers:\n",
    "        print(\"âŒ No valid tickers for beta calculation.\")\n",
    "        return\n",
    "\n",
    "    weights = np.array(weights)\n",
    "    weight_map = dict(zip(tickers, weights))\n",
    "    filtered_weights = np.array([weight_map[t] for t in valid_tickers])\n",
    "    filtered_weights = filtered_weights / filtered_weights.sum()\n",
    "\n",
    "    portfolio_beta = np.sum(filtered_weights * np.array(asset_betas))\n",
    "    portfolio_return = shock_pct * portfolio_beta\n",
    "    portfolio_cumulative = pd.Series([1.0, 1.0 + portfolio_return],\n",
    "                                     index=pd.date_range(end - timedelta(days=1), periods=2))\n",
    "\n",
    "    benchmark_returns_dict = {}\n",
    "    benchmark_cumulative_dict = {}\n",
    "\n",
    "    if benchmark_tickers:\n",
    "        for b in benchmark_tickers:\n",
    "            try:\n",
    "                b_prices = yf.download(b, start=start, end=end)['Close'].dropna()\n",
    "                b_returns = np.log(b_prices / b_prices.shift(1)).dropna()\n",
    "                aligned = pd.concat([b_returns, market_ret], axis=1).dropna()\n",
    "                beta = compute_beta(aligned.iloc[:, 0], aligned.iloc[:, 1])\n",
    "                b_simulated_return = beta * shock_pct\n",
    "                benchmark_returns_dict[b] = pd.Series([0, b_simulated_return],\n",
    "                                                      index=portfolio_cumulative.index)\n",
    "                benchmark_cumulative_dict[b] = pd.Series([1.0, 1.0 + b_simulated_return],\n",
    "                                                         index=portfolio_cumulative.index)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Benchmark {b} failed: {e}\")\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(portfolio_cumulative, label='Portfolio Simulated Return', color='crimson', linewidth=2)\n",
    "\n",
    "    for bmark, bmark_cum in benchmark_cumulative_dict.items():\n",
    "        ax.plot(bmark_cum, label=f'{bmark} Simulated Return', linestyle='--')\n",
    "\n",
    "    ax.set_title(f\"ðŸ“‰ Hypothetical Stress Test: {label}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Cumulative Return\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\nðŸ“Š Hypothetical Stress Test Summary\")\n",
    "    print(\"Scenario\".ljust(30), \":\", label)\n",
    "    print(\"Portfolio Return (%)\".ljust(30), \":\", round(portfolio_return * 100, 2))\n",
    "    print(\"Tickers Used\".ljust(30), \":\", \", \".join(valid_tickers))\n",
    "\n",
    "    for bmark, bret in benchmark_returns_dict.items():\n",
    "        sim_return = round((benchmark_cumulative_dict[bmark].iloc[-1] - 1) * 100, 2)\n",
    "        tracking_error = np.sqrt(np.mean((bret - portfolio_return) ** 2))\n",
    "        print(f\"{bmark} Simulated Return (%)\".ljust(30), \":\", sim_return)\n",
    "        print(f\"{bmark} Tracking Error\".ljust(30), \":\", round(tracking_error, 4))\n",
    "\n",
    "    return {\n",
    "        \"Scenario\": label,\n",
    "        \"Tickers Used\": valid_tickers,\n",
    "        \"Portfolio Simulated Return (%)\": round(portfolio_return * 100, 2)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad846c75-cb3b-4413-aa55-8525b76bf503",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summary = hypothetical_stress_test_sp500_shock(\n",
    "    tickers,\n",
    "    weights,\n",
    "    shock_pct=0.10,\n",
    "    label=\"S&P 500 +10%\",\n",
    "    benchmark_tickers=[\"^GSPC\", \"^IXIC\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df607690-2aff-42a7-b9f3-b18c7638a141",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summary_negative = hypothetical_stress_test_sp500_shock(\n",
    "    tickers,\n",
    "    weights,\n",
    "    shock_pct=-0.10,\n",
    "    label=\"S&P 500 -10%\",\n",
    "    benchmark_tickers=[\"^GSPC\", \"^IXIC\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313b45f-a139-448b-a1c7-da06a788a5df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def hypothetical_stress_test_rate_shock(tickers, weights, rate_change_pct=0.01, label=\"Interest Rate +1% Shock\", benchmark_tickers=None):\n",
    "    import yfinance as yf\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.dates as mdates\n",
    "\n",
    "    # 1. Fetch 1 year of daily returns for tickers and S&P 500 as rate proxy\n",
    "    returns = yf.download(tickers + ['^GSPC'], period='1y', interval='1d')['Close'].dropna().pct_change().dropna()\n",
    "    betas = {}\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if ticker in returns.columns:\n",
    "            cov = np.cov(returns[ticker], returns['^GSPC'])[0, 1]\n",
    "            var = np.var(returns['^GSPC'])\n",
    "            betas[ticker] = cov / var if var != 0 else 0\n",
    "\n",
    "    # 2. Simulate portfolio return based on rate_change_pct * beta\n",
    "    portfolio_return = sum(weights[i] * (rate_change_pct * -betas.get(ticker, 0)) for i, ticker in enumerate(tickers))\n",
    "    portfolio_cumulative = pd.Series([1.0, 1.0 + portfolio_return], index=pd.date_range(end=pd.Timestamp.today(), periods=2))\n",
    "\n",
    "    # 3. Benchmark assumptions (fixed impact)\n",
    "    benchmark_returns_dict = {}\n",
    "    benchmark_cumulative_dict = {}\n",
    "    if benchmark_tickers:\n",
    "        for bmark in benchmark_tickers:\n",
    "            bmark_impact = rate_change_pct * -0.5  # assume S&P drops 0.5% per +1% hike\n",
    "            sim_series = pd.Series([0.0, bmark_impact], index=portfolio_cumulative.index)\n",
    "            cum_series = pd.Series([1.0, 1.0 + bmark_impact], index=portfolio_cumulative.index)\n",
    "            benchmark_returns_dict[bmark] = sim_series\n",
    "            benchmark_cumulative_dict[bmark] = cum_series\n",
    "\n",
    "    # 4. Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(portfolio_cumulative, label='Portfolio Simulated Return', color='crimson', linewidth=2)\n",
    "\n",
    "    for bmark, cum in benchmark_cumulative_dict.items():\n",
    "        ax.plot(cum, label=f'{bmark} Simulated Return', linestyle='--')\n",
    "\n",
    "    ax.set_title(f\"ðŸ“‰ Hypothetical Stress Test: {label}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Cumulative Return\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Summary\n",
    "    summary = {\n",
    "        \"Scenario\": label,\n",
    "        \"Tickers Used\": tickers,\n",
    "        \"Portfolio Simulated Return (%)\": round(portfolio_return * 100, 2)\n",
    "    }\n",
    "\n",
    "    for bmark, bmark_ret in benchmark_returns_dict.items():\n",
    "        summary[f\"{bmark} Simulated Return (%)\"] = round((benchmark_cumulative_dict[bmark].iloc[-1] - 1) * 100, 2)\n",
    "        tracking_error = np.sqrt(np.mean((bmark_ret - portfolio_return) ** 2))\n",
    "        summary[f\"{bmark} Tracking Error\"] = round(tracking_error, 4)\n",
    "\n",
    "    print(\"\\nðŸ“Š Hypothetical Stress Test Summary:\")\n",
    "    print(f\"Scenario                  : {summary['Scenario']}\")\n",
    "    print(f\"Portfolio Return (%)      : {summary['Portfolio Simulated Return (%)']}%\")\n",
    "    print(f\"Tickers Used              : {', '.join(summary['Tickers Used'])}\")\n",
    "    for key in summary:\n",
    "        if key not in ['Scenario', 'Portfolio Simulated Return (%)', 'Tickers Used']:\n",
    "            print(f\"{key:30}: {summary[key]}\")\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f57c35-1a18-4d86-8d94-e5f874b1f8cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "summary = hypothetical_stress_test_rate_shock(\n",
    "    tickers=tickers,\n",
    "    weights=weights,\n",
    "    rate_change_pct=-0.01,  # For a -1% rate shock\n",
    "    label=\"Interest Rate -1% Shock\",\n",
    "    benchmark_tickers=[\"^GSPC\", \"^IXIC\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a584a-0446-42a1-a03d-ce51e932b473",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pprint\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"yfinance\").setLevel(logging.CRITICAL)\n",
    "\n",
    "def hypothetical_stress_test_rate_shock(tickers, weights, shock_pct=1.0, label=\"Interest Rate Shock\", benchmark_tickers=None):\n",
    "    # Step 1: Download historical price data (1 year)\n",
    "    data = yf.download(tickers, period='1y', interval='1d')['Close'].dropna(how='all', axis=1)\n",
    "    valid_data = data.dropna(axis=1)\n",
    "    available_tickers = valid_data.columns.tolist()\n",
    "\n",
    "    if len(available_tickers) == 0:\n",
    "        print(\"ðŸš« No tickers available for stress test.\")\n",
    "        return\n",
    "\n",
    "    filtered_indices = [tickers.index(t) for t in available_tickers]\n",
    "    filtered_weights = np.array(weights)[filtered_indices]\n",
    "    filtered_weights /= filtered_weights.sum()\n",
    "\n",
    "    # Step 2: Calculate log returns\n",
    "    returns = np.log(valid_data / valid_data.shift(1)).dropna()\n",
    "\n",
    "    # Step 3: Get interest rate proxy (10Y Treasury)\n",
    "    treasury = yf.download('^TNX', period='1y', interval='1d')['Close'].dropna()\n",
    "    treasury_returns = np.log(treasury / treasury.shift(1)).dropna()\n",
    "\n",
    "    # Step 4: Align returns with treasury\n",
    "    aligned_returns = returns.loc[returns.index.intersection(treasury_returns.index)]\n",
    "    treasury_returns = treasury_returns.loc[aligned_returns.index]\n",
    "\n",
    "    # Step 5: Calculate beta for each asset\n",
    "    betas = []\n",
    "    for ticker in aligned_returns.columns:\n",
    "        asset_ret = aligned_returns[ticker]\n",
    "        common_index = asset_ret.index.intersection(treasury_returns.index)\n",
    "        asset_ret = asset_ret.loc[common_index]\n",
    "        rate_ret = treasury_returns.loc[common_index]\n",
    "        cov = np.cov(asset_ret, rate_ret)[0, 1]\n",
    "        var = np.var(rate_ret)\n",
    "        beta = cov / var if var != 0 else 0\n",
    "        betas.append(beta)\n",
    "        print(f\"Beta for {ticker}: {beta:.4f}\")  # ðŸ” Print per-asset beta\n",
    "\n",
    "    # Step 6: Simulate return impact\n",
    "    simulated_returns = [beta * shock_pct for beta in betas]\n",
    "    portfolio_return = np.dot(simulated_returns, filtered_weights)\n",
    "    portfolio_cumulative = pd.Series([1.0, 1.0 + portfolio_return], index=pd.date_range(start=pd.Timestamp.today(), periods=2))\n",
    "\n",
    "    # Step 7: Benchmarks\n",
    "    benchmark_returns_dict = {}\n",
    "    benchmark_cumulative_dict = {}\n",
    "    if benchmark_tickers:\n",
    "        for bmark in benchmark_tickers:\n",
    "            try:\n",
    "                benchmark_prices = yf.download(bmark, period='1y', interval='1d')['Close'].dropna()\n",
    "                bmark_returns = np.log(benchmark_prices / benchmark_prices.shift(1)).dropna()\n",
    "                aligned_bmark = bmark_returns.loc[treasury_returns.index.intersection(bmark_returns.index)]\n",
    "                treasury_common = treasury_returns.loc[aligned_bmark.index]\n",
    "\n",
    "                cov = np.cov(aligned_bmark, treasury_common)[0, 1]\n",
    "                var = np.var(treasury_common)\n",
    "                bmark_beta = cov / var if var != 0 else 0\n",
    "\n",
    "                bmark_shock = bmark_beta * shock_pct\n",
    "                bmark_sim = pd.Series([1.0, 1.0 + bmark_shock], index=portfolio_cumulative.index)\n",
    "\n",
    "                benchmark_returns_dict[bmark] = pd.Series([0.0, bmark_shock], index=portfolio_cumulative.index)\n",
    "                benchmark_cumulative_dict[bmark] = bmark_sim\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Benchmark {bmark} failed: {e}\")\n",
    "\n",
    "    # Step 8: Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(portfolio_cumulative, label='Portfolio Simulated Return', color='crimson', linewidth=2)\n",
    "\n",
    "    for bmark, bmark_cum in benchmark_cumulative_dict.items():\n",
    "        ax.plot(bmark_cum, label=f'{bmark} Simulated Return', linestyle='--')\n",
    "\n",
    "    ax.set_title(f\"ðŸ“‰ Hypothetical Stress Test: {label}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Cumulative Return\")\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Step 9: Summary\n",
    "    summary = {\n",
    "        \"Scenario\": label,\n",
    "        \"Tickers Used\": available_tickers,\n",
    "        \"Portfolio Return (%)\": round(portfolio_return * 100, 2)\n",
    "    }\n",
    "\n",
    "    for bmark, bmark_ret in benchmark_returns_dict.items():\n",
    "        bmark_cum = benchmark_cumulative_dict[bmark]\n",
    "        summary[f\"{bmark} Simulated Return (%)\"] = round((bmark_cum.iloc[-1] - 1) * 100, 2)\n",
    "        tracking_error = np.sqrt(np.mean((bmark_ret - portfolio_return) ** 2))\n",
    "        summary[f\"{bmark} Tracking Error\"] = round(tracking_error, 4)\n",
    "\n",
    "    print(\"\\nðŸ“Š Hypothetical Stress Test Summary:\")\n",
    "    pprint.pprint(summary)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7415d4-b455-4483-b929-39f9ec13ad94",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Run the +1% interest rate shock\n",
    "summary = hypothetical_stress_test_rate_shock(\n",
    "    tickers=tickers,\n",
    "    weights=weights,\n",
    "    shock_pct=1.0,\n",
    "    label=\"Interest Rate +1% Shock\",\n",
    "    benchmark_tickers=[\"^GSPC\", \"^IXIC\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5c7b9-312d-46d5-bb3d-c9019e904f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119d436-f00d-477c-8dbc-3cdea1c174bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0cd60-b9e7-4bd8-9ece-1bb3c996cee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
